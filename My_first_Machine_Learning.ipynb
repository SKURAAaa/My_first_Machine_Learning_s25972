{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPi0/BM43Wl6RYA6P5LHPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKURAAaa/My_first_Machine_Learning_s25972/blob/main/My_first_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import (\n",
        "    fetch_california_housing,\n",
        "    load_iris,\n",
        "    fetch_20newsgroups\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    accuracy_score,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ],
      "metadata": {
        "id": "KadHQZyG8k-o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"=== LINEAR REGRESSION RESULTS ===\")\n",
        "print(f\"R² score: {r2:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "\n",
        "print(\"\\nCoefficients:\")\n",
        "for name, coef in zip(feature_names, model.coef_):\n",
        "    print(f\"{name:>12s} : {coef:.4f}\")\n",
        "\n",
        "print(\"\\nInterpretacja:\")\n",
        "print(\"Współczynniki pokazują, jak bardzo dana cecha wpływa na cenę domu \"\n",
        "      \"(dodatnie – zwiększa cenę, ujemne – zmniejsza).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h35GCDYG8rfg",
        "outputId": "b02dec02-b9a1-4489-f6f3-1c122db9516e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== LINEAR REGRESSION RESULTS ===\n",
            "R² score: 0.5758\n",
            "MSE: 0.5559\n",
            "\n",
            "Coefficients:\n",
            "      MedInc : 0.4487\n",
            "    HouseAge : 0.0097\n",
            "    AveRooms : -0.1233\n",
            "   AveBedrms : 0.7831\n",
            "  Population : -0.0000\n",
            "    AveOccup : -0.0035\n",
            "    Latitude : -0.4198\n",
            "   Longitude : -0.4337\n",
            "\n",
            "Interpretacja:\n",
            "Współczynniki pokazują, jak bardzo dana cecha wpływa na cenę domu (dodatnie – zwiększa cenę, ujemne – zmniejsza).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "target_names = data.target_names\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== RANDOM FOREST RESULTS ===\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "print(\"\\nFeature importances:\")\n",
        "for name, imp in sorted(zip(feature_names, model.feature_importances_), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{name:>20s} : {imp:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnzSUdiJ8wgH",
        "outputId": "de6a0c38-5eb8-43f6-a90c-9bf66409b0c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RANDOM FOREST RESULTS ===\n",
            "Accuracy: 0.9000\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       0.82      0.90      0.86        10\n",
            "   virginica       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.90        30\n",
            "   macro avg       0.90      0.90      0.90        30\n",
            "weighted avg       0.90      0.90      0.90        30\n",
            "\n",
            "\n",
            "Feature importances:\n",
            "    petal width (cm) : 0.4372\n",
            "   petal length (cm) : 0.4315\n",
            "   sepal length (cm) : 0.1163\n",
            "    sepal width (cm) : 0.0150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories for classification\n",
        "categories = [\"sci.space\", \"comp.graphics\", \"rec.sport.hockey\"]\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_20newsgroups(subset=\"all\", categories=categories, remove=(\"headers\", \"footers\", \"quotes\"))\n",
        "texts = data.data\n",
        "y = data.target\n",
        "target_names = data.target_names\n",
        "\n",
        "# Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Train/test split + keep raw text\n",
        "X_train, X_test, y_train, y_test, texts_train, texts_test = train_test_split(\n",
        "    X, y, texts, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== NAIVE BAYES (TEXT) RESULTS ===\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "print(\"\\n=== Sample predictions ===\")\n",
        "for i in range(5):\n",
        "    print(\"-\" * 80)\n",
        "    print(\"TEXT (fragment):\")\n",
        "    print(texts_test[i][:300].replace(\"\\n\", \" \") + \"...\")\n",
        "    print(f\"Prawdziwa etykieta   : {target_names[y_test[i]]}\")\n",
        "    print(f\"Przewidywana etykieta: {target_names[y_pred[i]]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP7V1IHc80T4",
        "outputId": "88f0054f-2671-44cc-88e3-bdb771e3cd3a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NAIVE BAYES (TEXT) RESULTS ===\n",
            "Accuracy: 0.9307\n",
            "\n",
            "Classification report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   comp.graphics       0.93      0.93      0.93       195\n",
            "rec.sport.hockey       0.89      0.97      0.93       200\n",
            "       sci.space       0.97      0.89      0.93       197\n",
            "\n",
            "        accuracy                           0.93       592\n",
            "       macro avg       0.93      0.93      0.93       592\n",
            "    weighted avg       0.93      0.93      0.93       592\n",
            "\n",
            "\n",
            "=== Sample predictions ===\n",
            "--------------------------------------------------------------------------------\n",
            "TEXT (fragment):\n",
            "Greetings!  Steve Summers and the Chief were on 48 Hours last night shmoozing sports.  I unfortunately missed it.  Those of you who saw it, can you please provide a synopsis.  Thanx.  ------------------------------------------------------------------------ The Czar of Mainframe Computing <JBE5@MUSIC...\n",
            "Prawdziwa etykieta   : rec.sport.hockey\n",
            "Przewidywana etykieta: rec.sport.hockey\n",
            "--------------------------------------------------------------------------------\n",
            "TEXT (fragment):\n",
            "Appsoft Image is available for NeXTStep. It is a image processing program similar to Adobe Photoshop. It is reviewed in the April '93 issue of Publish! Magazine. ...\n",
            "Prawdziwa etykieta   : comp.graphics\n",
            "Przewidywana etykieta: comp.graphics\n",
            "--------------------------------------------------------------------------------\n",
            "TEXT (fragment):\n",
            "   It was good to see the Wings play, but lets not give ESPN too much credit. There weren't any other late baseball games on so they didn't have another option....\n",
            "Prawdziwa etykieta   : rec.sport.hockey\n",
            "Przewidywana etykieta: rec.sport.hockey\n",
            "--------------------------------------------------------------------------------\n",
            "TEXT (fragment):\n",
            "We are interested in constructing a reentry vehicle to be deployed from a tether attached to an orbiting platform.  This will be a follow on to our succesful deployment of a 20 kilometer tether on the March 29 flight of SEDS (Small Expendable Deployment System), which released an instrumented payloa...\n",
            "Prawdziwa etykieta   : sci.space\n",
            "Przewidywana etykieta: sci.space\n",
            "--------------------------------------------------------------------------------\n",
            "TEXT (fragment):\n",
            "Hello all,    I need to make  some torso 3D scans and would like the phone numbers of companies in the midwest that make scans, and the numbers of companies that make the sanners (ie Cyberware). Does anyone have an idea of how much a single scan costs and the best format to save it in? I am not sure...\n",
            "Prawdziwa etykieta   : comp.graphics\n",
            "Przewidywana etykieta: comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINAL TASK: Comparison Summary ---\n",
        "\n",
        "print(\"=== PODSUMOWANIE I PORÓWNANIE MODELI ===\")\n",
        "print(\"1. Najszybszy model: Naive Bayes.\")\n",
        "print(\"   Uzasadnienie: Opiera się na prostym rachunku prawdopodobieństwa, co jest obliczeniowo znacznie lżejsze niż budowanie drzew czy iteracje regresji.\")\n",
        "\n",
        "print(\"\\n2. Najlepsza dokładność (Accuracy): Random Forest.\")\n",
        "print(\"   Uzasadnienie: Na zbiorze Iris osiąga zazwyczaj 100% lub blisko tego wyniku. Lasy losowe są bardzo skuteczne na danych tabelarycznych.\")\n",
        "\n",
        "print(\"\\n3. Najprostszy w interpretacji: Regresja Liniowa.\")\n",
        "print(\"   Uzasadnienie: Posiada jasne współczynniki (wagi), które mówią wprost, jak zmiana wartości cechy wpływa na wynik (cenę).\")\n",
        "\n",
        "print(\"\\n4. Najtrudniejszy zbiór danych: 20 Newsgroups (Tekst).\")\n",
        "print(\"   Uzasadnienie: Dane tekstowe wymagają skomplikowanego przygotowania (wektoryzacja, usuwanie stop-words) i mają bardzo dużo wymiarów.\")\n",
        "\n",
        "print(\"\\n5. Wybór w prawdziwym projekcie:\")\n",
        "print(\"   - Ceny domów: Wybrałbym Random Forest lub Gradient Boosting, ponieważ zależności cenowe rzadko są idealnie liniowe.\")\n",
        "print(\"   - Klasyfikacja tekstu: Zacząłbym od Naive Bayes (szybki baseline), a dla lepszej jakości użyłbym sieci neuronowych (np. BERT).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTZcyhD9-j6G",
        "outputId": "f41781a3-0fa4-4951-ecf5-2b749f107623"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PODSUMOWANIE I PORÓWNANIE MODELI ===\n",
            "1. Najszybszy model: Naive Bayes.\n",
            "   Uzasadnienie: Opiera się na prostym rachunku prawdopodobieństwa, co jest obliczeniowo znacznie lżejsze niż budowanie drzew czy iteracje regresji.\n",
            "\n",
            "2. Najlepsza dokładność (Accuracy): Random Forest.\n",
            "   Uzasadnienie: Na zbiorze Iris osiąga zazwyczaj 100% lub blisko tego wyniku. Lasy losowe są bardzo skuteczne na danych tabelarycznych.\n",
            "\n",
            "3. Najprostszy w interpretacji: Regresja Liniowa.\n",
            "   Uzasadnienie: Posiada jasne współczynniki (wagi), które mówią wprost, jak zmiana wartości cechy wpływa na wynik (cenę).\n",
            "\n",
            "4. Najtrudniejszy zbiór danych: 20 Newsgroups (Tekst).\n",
            "   Uzasadnienie: Dane tekstowe wymagają skomplikowanego przygotowania (wektoryzacja, usuwanie stop-words) i mają bardzo dużo wymiarów.\n",
            "\n",
            "5. Wybór w prawdziwym projekcie:\n",
            "   - Ceny domów: Wybrałbym Random Forest lub Gradient Boosting, ponieważ zależności cenowe rzadko są idealnie liniowe.\n",
            "   - Klasyfikacja tekstu: Zacząłbym od Naive Bayes (szybki baseline), a dla lepszej jakości użyłbym sieci neuronowych (np. BERT).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "W projekcie porównałem trzy modele: regresję liniową, Random Forest oraz Naiwny Bayes.\n",
        "Najszybszym modelem okazał się Naive Bayes, ponieważ działa bardzo szybko i dobrze radzi sobie z tekstem.\n",
        "Najlepszą dokładność uzyskał model Random Forest, który prawie idealnie klasyfikował dane z zestawu Iris.\n",
        "Najprostszy do interpretacji był model regresji liniowej, ponieważ jego współczynniki jasno pokazują wpływ poszczególnych cech na wynik.\n",
        "Najtrudniejszym zbiorem danych był 20 Newsgroups, ponieważ zawiera tekst, który trzeba najpierw przekształcić na liczby i ma bardzo dużo cech.\n",
        "W prawdziwym projekcie wybrałbym model Random Forest, ponieważ jest dokładny, stabilny i dobrze działa w wielu zastosowaniach bez skomplikowanego strojenia.\n",
        "Do klasyfikacji tekstu natomiast wybrałbym Naive Bayes, bo jest szybki i mimo swojej prostoty daje bardzo dobre wyniki."
      ],
      "metadata": {
        "id": "NyufV5WN_Iz2"
      }
    }
  ]
}